{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf1bb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:86% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:15pt;}\n",
       "div.output {font-size:15pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:15pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:15px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:86% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:15pt;}\n",
    "div.output {font-size:15pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:15pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:15px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eead63",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2. LLM활용의 기본 개념(Ollama)</span>\n",
    "\n",
    "# 1. LLM을 활용하여 답변하기\n",
    "\n",
    "## 1) Ollama 이용한 로컬 LLM 이용\n",
    "성능은 GPT, Claude 같은 모델보다 떨어지나, 개념 설명을 위해 open source 모델 사용\n",
    "\n",
    "### a) ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama pull deepseek-r1:1.5b (window키 + R => powershell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9b9bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nKorea's main city and the largest city in South Korea is首尔 (Pusan). Other major cities include Seoul, Busan, Gwangju, and Gyeonggi-Do.\", additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-06-25T02:15:31.8457583Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3584881600, 'load_duration': 1054115300, 'prompt_eval_count': 10, 'prompt_eval_duration': 231773500, 'eval_count': 45, 'eval_duration': 2297716000, 'model_name': 'deepseek-r1:1.5b'}, id='run--fc0a0604-cc6a-4239-876e-967084c1773c-0', usage_metadata={'input_tokens': 10, 'output_tokens': 45, 'total_tokens': 55})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke(\"what is the capital of Korea?\")\n",
    "result # 추론모델<think>~<think>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0d485",
   "metadata": {},
   "source": [
    "### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama run llama3.2:1b (window키+R => powershell)\n",
    "- llama : 공식적으로 한글지원 안됨 (llama3.1 405b한글지원 가능 -> llama3.3 70b)\n",
    "- exaone : 공식적으로 한글지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a55457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that there are also two other cities that serve as co-capital cities: Pusan (also known as Busan) in the south and Incheon in the north. But Seoul remains the de facto capital.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T02:17:41.8971346Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6259895300, 'load_duration': 2453067400, 'prompt_eval_count': 32, 'prompt_eval_duration': 561985300, 'eval_count': 56, 'eval_duration': 3242921500, 'model_name': 'llama3.2:1b'}, id='run--c5f075c9-9b87-4b67-bf15-7580679542ca-0', usage_metadata={'input_tokens': 32, 'output_tokens': 56, 'total_tokens': 88})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "result = llm.invoke(\"what is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fc924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital of South Korea is Seoul. However, it's worth noting that there are also two other cities that serve as co-capital cities: Pusan (also known as Busan) in the south and Incheon in the north. But Seoul remains the de facto capital.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ac1c473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고속도트란트를 통해 전 세계로 이동할 수 있는 한국의 수도는 Seoul입니다. 서울은 한국의 제1의 도시로, 주로 동경을 가로지르면서 유명합니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(\"한국 수도는 어디야?\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f2c03",
   "metadata": {},
   "source": [
    "## 2) openai 활용\n",
    "- pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f0c6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# result = llm.invoke(\"what is the capital of Korea?\")\n",
    "# result => 에러 이유 : OPENAI_API_KEY 환경변수 부재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e17149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e2b286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩에서 OPENAI_API_KEY 읽기(.env 못씀)\n",
    "# 보안키 추가 후\n",
    "# from google.colab import userdata\n",
    "# userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5eb880f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 18, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BmCpQAIaBF3WgzPtIgOFoEKhxl0Se', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0828844f-ee90-47df-86d4-a3ceb2f1d77b-0', usage_metadata={'input_tokens': 18, 'output_tokens': 7, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\",\n",
    "#                  openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "                )\n",
    "llm.invoke(\"what is the capital of Korea? Answer me in Korean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "febd3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델의 키가 OPENAI_API_KEY는 아님\n",
    "# Claude -> Anthropic\n",
    "# Azure, upstage, Bedrock : 에러 메세지 참조하여 환경변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63388308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model=\"gpt-4.1-nano\")\n",
    "# 에러를 내면 OPENAI_API_VERSION 환경변수가 필요하는 메세지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b25150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_anthropic import ChatAnthropic\n",
    "# llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# llm.invoke(\"what is the capital of korea\")\n",
    "\n",
    "# headers = self._build_headers(options, retries_taken=retries_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9c827",
   "metadata": {},
   "source": [
    "# 2. 렝체인 스타일로 프롬프트 작성하기\n",
    "- 프롬프트 : llm 호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1283164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "# llm.invoke(0)\n",
    "# 프롬프트 타입 : str, PromptValue, BaseMessages리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51930a39",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a099e00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of Korea'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T05:32:29.2545349Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2427847100, 'load_duration': 1400126300, 'prompt_eval_count': 31, 'prompt_eval_duration': 523449400, 'eval_count': 9, 'eval_duration': 502419600, 'model_name': 'llama3.2:1b'}, id='run--4aad2588-eff8-4502-ae1a-59ba7b963aeb-0', usage_metadata={'input_tokens': 31, 'output_tokens': 9, 'total_tokens': 40})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}\", # {}안의 값을 새로운 값으로 할당 가능\n",
    "    input_variables = [\"country\"],\n",
    ")\n",
    "prompt = prompt_template.invoke({\"country\":\"Korea\"})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9a24d",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속 받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05fb8259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You ara a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Korea?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Seoul.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of {country}?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list =[\n",
    "    SystemMessage(content=\"You ara a helpful assistant!\"),\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),\n",
    "    HumanMessage(content=\"What is the capital of Korea?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of {country}?\")\n",
    "]\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages(message_list)\n",
    "prompt = chatPromptTemplate.invoke({'country':'Korea'})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c2873",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage 리스트 -> 튜플 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dd0e651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?한국\n",
      "프롬프트 : messages=[SystemMessage(content='You ara a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of 한국?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of 한국 (South Korea) is Seoul.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage를 수정\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You ara a helpful assistant!\"),\n",
    "    (\"human\", \"What is the capital of {country}?\"),\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt = chatPromptTemplate.invoke({\"country\":country})\n",
    "print(\"프롬프트 :\",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "072a68bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?korea\n",
      "프롬프트 : messages=[SystemMessage(content='당신은 대한민국 전문 도우미야!', additional_kwargs={}, response_metadata={}), HumanMessage(content='korea의 수도가 어디예요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'한국의 수도는 Seoul입니다.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage를 수정\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대한민국 전문 도우미야!\"),\n",
    "    (\"human\", \"{country}의 수도가 어디예요?\"),\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt = chatPromptTemplate.invoke({\"country\":country})\n",
    "print(\"프롬프트 :\",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e13892",
   "metadata": {},
   "source": [
    "# 3. 답변 형식을 컨트롤하기\n",
    "- invoke 실행결과는 AIMessage() -> String이나 json, 객체 : outParser이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3856f16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 : text='What is the capital of korea. Return the name of the city only'\n",
      "llm 결과 : <class 'langchain_core.messages.ai.AIMessage'> content='Seoul' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T06:40:07.9680672Z', 'done': True, 'done_reason': 'stop', 'total_duration': 204941800, 'load_duration': 24804500, 'prompt_eval_count': 40, 'prompt_eval_duration': 60428100, 'eval_count': 3, 'eval_duration': 118711600, 'model_name': 'llama3.2:1b'} id='run--a1889aff-e3e3-4c59-9f95-f8d03748b57c-0' usage_metadata={'input_tokens': 40, 'output_tokens': 3, 'total_tokens': 43}\n",
      "파서 결과 : Seoul\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\":\"korea\"})\n",
    "print(\"프롬프트 :\", prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(\"llm 결과 :\", type(result), result)\n",
    "# 문자열 출력 파서를 이용하여 llm 응답을 단순 문자열 반환\n",
    "output_parser = StrOutputParser()\n",
    "print(\"파서 결과 :\", output_parser.invoke(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c6263c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83d552f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate(변수설정) => ChatPromptTemplate(변수설정, system과 모범답안 지정)\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"you are a helpful assistant with expertise in South Krea.\"),\n",
    "    (\"human\", \"what is the capital of {country}? Return the name of the city only.\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2aa544",
   "metadata": {},
   "source": [
    "## 2) JSON 출력 파서 이용\n",
    "- json()으로 응답하기를 원하지만, 우선 어떤 형식으로 반환되는지 확인\n",
    "{\"name\":\"홍\", \"age\":22}(json)/{'name':'홍', 'age':22}(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6d2afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'> content='```\\n{\\n    \"capital\": \"Seoul\",\\n    \"population\": 51.8,\\n    \"language\": \"Korean\",\\n    \"currency\": \"KRW\"\\n}\\n```' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T07:02:37.4858505Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2369746300, 'load_duration': 38076400, 'prompt_eval_count': 59, 'prompt_eval_duration': 62836600, 'eval_count': 39, 'eval_duration': 2268305100, 'model_name': 'llama3.2:1b'} id='run--00509020-905b-4649-a60d-c01a73e47641-0' usage_metadata={'input_tokens': 59, 'output_tokens': 39, 'total_tokens': 98}\n",
      "<class 'dict'> {'capital': 'Seoul', 'population': 51.8, 'language': 'Korean', 'currency': 'KRW'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dict only\"\"\",\n",
    "    input_variables= [\"country\"]\n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "print(type(prompt))\n",
    "# JSON output 파서\n",
    "output_parser = JsonOutputParser()\n",
    "ai_message = llm.invoke(prompt)\n",
    "print(type(ai_message), ai_message)\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(type(json_result), json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d98e889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Seoul',\n",
       " 'population': 51.75,\n",
       " 'language': 'Korean',\n",
       " 'currency': 'South Korean won'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dict only\"\"\",\n",
    "    input_variables= [\"country\"]\n",
    ")\n",
    "output_parser = JsonOutputParser()\n",
    "info = output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"})))\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b19d70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8c722",
   "metadata": {},
   "source": [
    "## 3)  구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM 출력을 구조화된 형식으로 받기(JsonParser 보다 훨씬 안정적)\n",
    "- Pydantic : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5213f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x000002056778B160>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "user = User(1, \"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f193934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>0, ge=0:id>=0, lt=0:id<0, le=0:le<=0\n",
    "    id:int   = Field(gt=0,            description=\"id\")\n",
    "    name:str = Field(min_length=2,    description=\"name\")\n",
    "    is_active:bool=Field(default=True,description=\"id활성화\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e5e98d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dict only\"\"\",\n",
    "    input_variables= [\"country\"]\n",
    ")\n",
    "class CountryDetail(BaseModel):   # description: 더 정확한 출력 유도\n",
    "    capital:str     = Field(description=\"the capital of the country\")\n",
    "    population:int  = Field(description=\"the population of the country\")\n",
    "    language:str    = Field(description=\"the language of the country\")\n",
    "    currency:str    = Field(description=\"the currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "\n",
    "# output_parser = JsonOutputParser()\n",
    "# output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"})))\n",
    "\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e254e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital='Seoul' population=51 language='Korean' currency='South Korean won'\n",
      "Seoul 51\n"
     ]
    }
   ],
   "source": [
    "print(info)\n",
    "print(info.capital, info.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "769a5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"South Korean won\"}\n",
      "info를 dict : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print('info를 json :', info.model_dump_json()) # json()함수는 조만간 없어질 예정\n",
    "print('info를 dict :', info.model_dump()) # dict()함수는 조만간 없어질 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372dea73",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 렝체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9938ed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\",\n",
    "                temperature=0) # 일관된 답변\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1245fa",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자(|)사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dced0b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> LLM -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\":\"Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fc4737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(capital_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e88a593",
   "metadata": {},
   "source": [
    "## 3) 복합 체인 구성\n",
    "- 여러단계의 추론이 필요한 경우 ( 체인 연결 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c4aa77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 입력 -> 나라명 출력\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "country_prompt = PromptTemplate(\n",
    "    template = \"\"\"Guess the name of the country based on the follwing information:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=[\"\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                       \"This country is very famous for its wine\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91f6a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추측 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "# type(country_chain)\n",
    "country_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d38a5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나라설명 -> 나라명 -> 나라 수도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f823e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719cc265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = {\"country\" : country_chain} | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbeba6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\":RunnablePassthrough()} | \\\n",
    "                {\"country\":country_chain} | capital_chain\n",
    "final_chain.invoke(\"This country is very famous for its wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51dac301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿에 변수 2\n",
    "# 나라설명 -> 나라명\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "country_prompt = PromptTemplate(\n",
    "    template = \"\"\"Guess the name of the country in the {continent} based \n",
    "    on the follwing information:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=[\"information\", \"continent\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                       \"This country is very famous for its wine\",\n",
    "                                                      \"continent\":\"Europe\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c9f5ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = {\"country\" : country_chain} | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\",\n",
    "                   \"continent\":\"Europe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a97fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ba8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 나라명 -> (제일 유명한 음식 ->) 음식의 레시피 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8fea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ceb703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e902b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca851491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
